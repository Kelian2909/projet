{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81eb6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52208676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsing_keystats\n",
    "import stock_prediction\n",
    "import current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d29cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_sample_dimensions():\n",
    "    \"\"\"\n",
    "    Check that the forward sample has been built correctly\n",
    "    \"\"\"\n",
    "    # Number of features + ['Date', 'Unix', 'Ticker', 'Price', 'stock_p_change', 'SP500', 'SP500_p_change']\n",
    "    df = pd.read_csv('forward_sample.csv')\n",
    "    indexing_columns = ['Date', 'Unix', 'Ticker', 'Price',\n",
    "                        'stock_p_change', 'SP500', 'SP500_p_change']\n",
    "    n_cols = len(df.columns)\n",
    "    assert n_cols == len(current_data.features) + len(indexing_columns)\n",
    "    assert len(df) == len(os.listdir('forward/'))\n",
    "    indexing_columns.remove('Ticker')\n",
    "    # Make sure that all of the indexing columns only contain zeroes\n",
    "    assert df[indexing_columns].sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f96369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_sample_data():\n",
    "    \"\"\"\n",
    "    Some quick checks on the forward sample data\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('forward_sample.csv')\n",
    "    # For these tests we need to fill in nan values with zero\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # Make sure that these features have positive values\n",
    "    positive_features = ['Market Cap', 'Price/Sales', 'Revenue', 'Revenue Per Share', 'Total Cash',\n",
    "                         'Total Cash Per Share', 'Total Debt', '50-Day Moving Average', '200-Day Moving Average',\n",
    "                         'Avg Vol (3 month)', 'Shares Outstanding', 'Float',\n",
    "                         '% Held by Insiders', '% Held by Institutions', 'Shares Short',\n",
    "                         'Short Ratio', 'Short % of Float', 'Shares Short (prior month']\n",
    "    assert all(df[positive_features] >= 0)\n",
    "\n",
    "    # Make sure that these features have values less than 100 (the above checks that they are +ve)\n",
    "    fractional_features = ['% Held by Insiders', '% Held by Institutions',\n",
    "                           'Short Ratio', 'Short % of Float']\n",
    "    assert all(df[fractional_features] <= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9858db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stock_prices_dataset():\n",
    "    \"\"\"\n",
    "    Check that data from pandas-datareader has been downloaded correctly\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(\"stock_prices.csv\", index_col='Date', parse_dates=True)\n",
    "    assert type(df.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "    # Make sure that all columns have some price data\n",
    "    assert all(df.isnull().sum() < len(df))\n",
    "    # After this, we fill in missing values with zero for test purposes\n",
    "    df.fillna(0, inplace=True)\n",
    "    assert all(df >= 0)\n",
    "\n",
    "    # Index prices\n",
    "    index_df = pd.read_csv(\n",
    "        \"sp500_index.csv\", index_col='Date', parse_dates=True)\n",
    "    assert type(df.index) == pd.core.indexes.datetimes.DatetimeIndex\n",
    "    assert len(index_df.columns) == 6\n",
    "    assert index_df.shape[0] == df.shape[0]\n",
    "    assert index_df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d134ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_keystats_dimensions():\n",
    "    \"\"\"\n",
    "    This tests that the keystats csv has been built correctly\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"keystats.csv\", index_col='Date')\n",
    "\n",
    "    indexing_columns = ['Unix', 'Ticker', 'Price',\n",
    "                        'stock_p_change', 'SP500', 'SP500_p_change']\n",
    "    n_cols = len(df.columns)\n",
    "    assert n_cols == len(parsing_keystats.features) + len(indexing_columns)\n",
    "\n",
    "    # No missing data in the index columns\n",
    "    assert df[indexing_columns].isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47579c54",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def test_stock_prediction_dataset():\n",
    "    \"\"\"\n",
    "    This tests that the dataset on which we are training our algorithm has been correctly built\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"keystats.csv\", index_col='Date')\n",
    "    num_rows_with_nan = sum(df.isnull().sum(axis=1) > 0)\n",
    "\n",
    "    X, y = stock_prediction.build_data_set()\n",
    "    assert X.shape[0] == df.shape[0] - num_rows_with_nan\n",
    "    assert len(y) == df.shape[0] - num_rows_with_nan\n",
    "    assert X.shape[1] == len(parsing_keystats.features)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
